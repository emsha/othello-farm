=======================================================
Saturday, April 13, 2019

I would like to make an othello player. She will be a neural network of some kind. She will be born of fire, brought up in a world of competition, survival of the fittest. From many generations of similar nets, she will be the one who rises above the rest. 

Todo:

- set up othello gameplay
- initialize neural net
- create structure for training generations
- how do we make a new generation from an old generation? consider mutations

for today (apr 13), I will set up othello gameplay.


=======================================================
tues apr 30 2019:
I just made it so I can play n games from god between two players, and store all the winning moves paired up with the state from which the move was played. (state_in, move_out), stored in net tensor form (3 channel 100 elt padded images with channels being my pieces, their pieces, legal moves,,,,,,,64 elt list of all zeroes and a 1 where the move was made, corresponding with the coord of the move)

new stuff:

State.output_tensor_to_coords(t)	-> 			2 tuple
State.coords_to_output_tensor(p)	-> 			tensor
State.state_to_padded_input_tensor(state)	->	tensor
game.play()

next stuff:

get net to take in stuff, put out stuff, make it all line up
then test on training. make a pair, teach it to learn one move 

=======================================================
sunday may 5, 2019

i can train it in batches now. playing with generating moves and training populations.

next steps: 
- refactor so that everything is a tensor, all of the game (cuda!)
- mutate, crossover, evolve population
	- decide: change hyperparameters too, or just weights? read
- save and load nets to and from file
- set up large populations and train and test. 
- fine tune


=======================================================
monday may 6 2019

the things i want to do today:
- save/load net DONE
- understand optimizer and criterion
	- do i need to make new ones everytime i train? what information is stored?
	DONE:? decided to store it with the net, in case i end up having different ones for different nets
- make git repo DONE
- read up on genetic evolution of nets, hyperparams, weights, strategies, good and bad practices?

cuda won't work because macs are dumb. :(

=======================================================
Tuesday May 7

I'm thinking about the repopulate step in this world. Is there a way to make a somewhat trained new net from an old net, where the new net has different hyperparameters? like a different shape? the amt of training per generation has to be enough such that a net with new hyperparameters can 'catch up' to ones that have preserved mostly the weights and shapes from the past successful ones, otherwise there won't be much opportunity for hyperparameter exploration.

Finally fixed torch issue, I had uninstalled and reinstalled torch so I could try and get CUDA...turns out that's hard, so I reinstalled it with pip like i did previously, but now after reinstalling, there was an import error. I fixed it by uninstalling both torch and torchvision, and reinstalling the previous version 1.0.0 instead of 1.0.1. That fixed the issue. Then I reinstalled torchvision, and my god.py works again! Strange issue, couldn't make much sense of the posted issues, though it seems other users have had this issue too. 

http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.28.5457&rep=rep1&type=pdf

NEAT = NeuroEvolution of Augmenting Topologies (topology = structure of net)

this paper argues: "if done right, evolving structure along with connection weights can significantly enhance the performance of NE[neuro evolution]" (p2)

questions:
- is there a way to crossover different topologies in an effective way?
- how can we 'ensure' that an innovation in a population doesn't die out? like if the innovation needs a few generations to 'mature'
- minimize topologies throughout evolution without a fitness fn that measures complexity?

- crossover?? to mate or not to mate? the binary scale lol. seems that crossover isn't necessary, and can get complicated when considering the offspring of two nets with different topologies. feeling like i will omit crossover from my program, at least to start

so next question: how do we encode the cnn so we can then mutate and make new buddies to repopulate the farm?

another question: an innovation in topology can lead to a decrease in fitness at first, but after a few generations, the new shape could prove to be more effective. how to protect this innovation?
	- one idea: GNARL system, adds 'nonfunctional' structure, not sure what this means, maybe is it that  when it's first added, it won't affect the performance, and only once it learns, itll change the behavior? (Start with zero'd weights?)
		- problem with this is, it may never integrate
- NEAT's solution: SPECIATION
	- uses historical info about genes to group into species
	- explicit fitness sharing forces similar genome'd buddies to share fitness payoff
	- this way, the similar buddies can band together and be more robust than if they were alone. LIVE TOGETHER OR DIE ALONE #lost

- cool idea: incorporate net size into fitness score to reward simpler configurations
	- but this can be randomly decided by whoever is playing god, and this feels unnatural, could lead to suboptimal performance based on the decisions of the Creator

- if we start out minimally, however, this will help keep our population from getting unecessarily huge architectures, and larger ones should emerge naturally and gradually from evolution

SO.......
NEAT combines all of these ideas.



so lots of info.... lots of optimizations. maybe for the first iteration of this program, i'll just mutate weights. 

--
also new thing SNN (spiking neural network) i'm intrigued.

--
so anyway, POINT MUTATIONS:
i need a representation of the net where I can iterate through weights and randomly change some of those using a function

what could the fn be?
m = mutation rate (chance that a weight is changed)

def mutate(w):
	m = random.randint(100) #says if this weight will be mutated
	r=0
	if m==0:
		r = random.normalvariate(0, 1)/100
	return r+w


also another refactor: put the minimax in tensors...already is nuts

next things: ConvNet.copy(net, mutate=False)
also make mutation in tensors, adding tensors rather than iterating, should be much faster. how to make tensor of a size with random floats or even ints within range, then element wise addition bro

---------------------
=======================================================
Wed May 8, 2019

Today I did a few things. I added pointwise mutation using tensors and shapes. It works like this:

in ConvNet:

def clone(self, mutations=False)
@staticmethod
    def generate_mutations(net_layer, bound, rate_denom)

clone returns a copy of a net potentially with point mutations
generate_mutations makes a tensor the same shape as net_layer, with zeros everywhere excpt for where the values of random mutations occur.
this outputed tensor should be added element wise to net.layer.weight.data by using tensorA.add_(tensorB). This is the new mutated weights.

in god.py:

added:
	eval_pop_random -> returns score, results of tests against random players
	repopulate -> edits pop arg in place, preserves top_n nets based on results, and replaces bottom of population with mutated versions of the top one
	gen_pop -> generates population, returns list of nets

	progressbar!

also cleaned up code and printing.

todo next: hyperparams? make mutation robust to changing shapes, play with learning rate, mutation rate, mutation range, basically get this to be faster than it is pls

another thing i'm thinking about:

i was considering as a next baby step in the mutation process, keeping populations of nets that start from the same place, and train with different learning rates and epoch values. adn then choosing the best after the training, copying it exactly, then training the next gen with those same combos of parameters as the one before ex:
train all same start weights -> [lr=.001, lr=.002, lr=.01], choose best, copy best one to all spots, then train again with those ^ weights. 

anywayyyyyy: 

was thinking about efficiency/best use of resources. when is evolution the best use of time and computation? like could i be spending this time training one larger net a lot more and get it better than anything that the evolution would make? i guess that's the point of the evolution, is for it to be worth it, and to explore more than anything non-evolutionary could do. 

mine's not worth it right now... lol

also mutations to things like batch size, epochs, learning rate, things like that. shouldn't be too hard
=======================================================

Thurs May 9, 2019

I'm thinking about the way that I've approached this problem so far. I want validation. I think I may train one net on a few hyperparameters and see how it responds. Just to try to get one up to 90% winrate against a random mover. 

After that, I'll make it so batch size, epochs, learning rate, loss fn. 

Then, I'll start adding more conv filters, initialized to 1 when they're added.

here's an idea:

the architecture now is :

input -> conv(64 3x3 filters w/ padding) -> fully connected -> fully connected->output

I'll add a second conv layer that starts off with one layer?

ok, added a second layer, it works better i think. havent done extensive testing yet. 

buttt

late night changes: made progress bar move in smaller increments. made it and its value a global variable TRY AND STOP ME u wont. on the surface, this change may seem superficial (lol), however; with large amounts of games, data, and buddies in bigger populations and longer trains, a progress bar that changes at least once a minute is really nice to have. 

Also print all values at start of train to potentially save output and know these values ok nice.

ALSO changed mutation rate and range to be less frequent and smaller.
=======================================================
Sunday May 12, 2019

I want to test the evolution part with data that's faster to verify. Generating games takes forever. I think the mutation and hyperparams is the important part of this project. So I'm going to start a sub project to set the buddies classifying images. This should be faster, and a good way to test if some mutation and evolution ideas can work. Plus, image labeling is a simpler problem than game playing (I think). 

First hyperparameter idea: adding convolutional filters initialized to all 1's. 
steps:
- add layers to a list, so I could theoretically add layers, and be looping through them when forward propogating
- hook up numbers so I could add a conv filter
today: find some photos pls
gonna use
cifar-10 dataset

from http://www.cs.toronto.edu/~kriz/cifar.html
citation: Learning Multiple Layers of Features from Tiny Images, Alex Krizhevsky, 2009.

may 12 nighttime, 23:56, just set up cifar10 training. used the quick tutorial on pytorch and it's training now. Getting it ready to be mutated yo.

gn moon
=======================================================
Monday May 20, 2019

Next step: add conv filter addition. this means, if the mutation should occur, we add an extra filter in a random conv layer. initialize to all 1's. To do this: need to make the hyperparameters in the layers match up, need to figure out how to presreve weights from old net/add a filter of all ones. 
=======================================================
Thurs May 23, 2019

How to encode a net?


right now, the net is simple:
input -> conv layer(s) -> fully connected layer(s) -> output
so, our encoding will be two lists, the first encoding info for the conv layers, and the second for the fc layers
conv layer list structure: [{inputs, outputs, kernel size, padding}, 

scratch this^^

ok, i found this:

https://discuss.pytorch.org/t/dynamically-expandable-networks-resizing-weights-during-training/19218


so todo now:

start with very simple architecture, make init take parameters, i think this will be useful, or at least make a version that does so you understand the parameters of the shapes and the internal structure so that when you go in and fucks with it it will be correct. also read the above link, and maybe paper associated with it. thank you and goodnight.
........
okay so i read up on some stuff here it is ok nice. nn.sequential vs nn.module vs nn.modulelist vs nn.parameterlist vs all the other stuff. i think there's a way that the init of my net can use a list, so i dont have to do encoding myself. also using exec() is horrible and not working. :( i think i can use one of those. to simplify things, i won't change the fc layer. I'll have the final convolutional layer feed into the fc layer, and have the fc layer never change. or wait no. just have the boundries never change. for example: conv1, conv2(changable) ... conv_last(outputs never change), fc1 (inputs constant), fc... fc final (outputs to poutputs. ok)

that way, i only have one spot that's different. but this shouldn't be an issue if i can figure out how to use the sequential and/or module ./module list or whatever thing i end up useing porperly.
=======================================================
May 27 2910
** may 27 2019

ok good start^ lol. I'm going to try to make a custom layer class that will build off of the Conv2d class. I'm going to add a clone function that clones with possible mutation of adding a filter initialized to all 1's. 

ok maybe not. still reading and absorbing info and thinking. not ready to implement anything just yet. 

https://medium.com/@stathis/design-by-evolution-393e41863f98
 I have a feeling this^ shit is good shit ya feel

=======================================================
May 30, 2019

I finished implementing the custom model class from the medium article, and adapted it to my model with the conv layers then the fc layer. I finally figured out how to compute the input to the first fc layer. yayayayayayayay. good shit good shit good shit boi.


ideas for mutation

- im so close to being able to add a filter. i think i know how now. so...
rules for mutation:
	CLONE() can mutate in a few ways:
		- point mutation
		- add a filter to one or multiple conv layers
		- add a new conv layer 
		- add a new fc layer
		- add a new node in the fc layer
		- change activation fn
		- change dropout

so each of these things has to have a lower bound, upper bound, a rate, and data type. need to implement new custom mutate functions. aka, instead of if mutate: sample, it's gonna be if mutate: grow/increment. can keep random sampling for initial inits, but for growing, should be pretty incremental i think
=======================================================
may 31 2019 

goal for today: implement clone method that can add a filter to the first conv layer.
found a bug in def compute_initial_fc_inputs(build_info, image_s):
fixed it
implemented clone, testing it now
feel ike im being very hacky rn. i'll clean it up later. bad practice, but some of these things I still don't understand fully. 

I'm doing a test: training and testing a net, then cloning it and training and testing it again, this time with the extra filter, let's see how much better it'll do, no wait abort.

here's my test for today:

I train nett, then i clone him, and test nett_clone and nett
they should behave similarly since new weights were initialized to 1. after this i'm done for the day I think


here's the test output: maxshashoua@Maxs-MBP-2:~/Documents/Developer/othellofarm$ python3 exp.py 
previous_units: 2916


set up data:
Files already downloaded and verified
Files already downloaded and verified
training a net
/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
[1,  2000] loss: 2.316
[1,  4000] loss: 2.306
[1,  6000] loss: 2.300
[1,  8000] loss: 2.291
[1, 10000] loss: 2.284
[1, 12000] loss: 2.279
^[f[2,  2000] loss: 2.271
[2,  4000] loss: 2.264
[2,  6000] loss: 2.258
[2,  8000] loss: 2.252
[2, 10000] loss: 2.246
[2, 12000] loss: 2.237
previous_units: 3645
Sequential(
  (conv_0): Conv2d(3, 4, kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
  (relu_0): ReLU()
  (flatten): Flatten()
  (fc_0): Linear(in_features=2916, out_features=196, bias=True)
  (dropout_0): Dropout(p=0.667209393568471)
  (sigm_0): Sigmoid()
  (classification_layer): Linear(in_features=196, out_features=10, bias=True)
  (sofmax): LogSoftmax()
) Sequential(
  (conv_0): Conv2d(3, 5, kernel_size=(8, 8), stride=(1, 1), padding=(1, 1))
  (relu_0): ReLU()
  (flatten): Flatten()
  (fc_0): Linear(in_features=3645, out_features=196, bias=True)
  (dropout_0): Dropout(p=0.667209393568471)
  (sigm_0): Sigmoid()
  (classification_layer): Linear(in_features=196, out_features=10, bias=True)
  (sofmax): LogSoftmax()
)
Accuracy of the network on the 10000 test images: 21 %
Accuracy of plane : 40 %
Accuracy of   car : 10 %
Accuracy of  bird :  5 %
Accuracy of   cat : 15 %
Accuracy of  deer :  6 %
Accuracy of   dog : 13 %
Accuracy of  frog : 45 %
Accuracy of horse :  7 %
Accuracy of  ship : 41 %
Accuracy of truck : 32 %
Accuracy of the network on the 10000 test images: 10 %
Accuracy of plane :  0 %
Accuracy of   car :  0 %
Accuracy of  bird :  1 %
Accuracy of   cat : 16 %
Accuracy of  deer :  4 %
Accuracy of   dog :  0 %
Accuracy of  frog :  1 %
Accuracy of horse :  0 %
Accuracy of  ship : 79 %
Accuracy of truck :  2 %


the second net was the clone. so...maybe init to values very close to 0?
lemme try init'ing to zero

initting to zero, training net 1, cloning after train, testing output:
this test was to see the diff between the trained net and the net cloned from the trained net, how good is it purely from the clone?
maxshashoua@Maxs-MBP-2:~/Documents/Developer/othellofarm$ python3 exp.py 
previous_units: 3364


set up data:
Files already downloaded and verified
Files already downloaded and verified
training a net
/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
[1,  2000] loss: 2.024
[1,  4000] loss: 1.877
[1,  6000] loss: 1.821
[1,  8000] loss: 1.790
[1, 10000] loss: 1.774
[1, 12000] loss: 1.751
[2,  2000] loss: 1.722
[2,  4000] loss: 1.712
[2,  6000] loss: 1.730
[2,  8000] loss: 1.697
[2, 10000] loss: 1.698
[2, 12000] loss: 1.696
previous_units: 4205
Sequential(
  (conv_0): Conv2d(3, 4, kernel_size=(6, 6), stride=(1, 1), padding=(1, 1))
  (tanh_0): Tanh()
  (flatten): Flatten()
  (fc_0): Linear(in_features=3364, out_features=327, bias=True)
  (dropout_0): Dropout(p=0.39121718688057483)
  (classification_layer): Linear(in_features=327, out_features=10, bias=True)
  (sofmax): LogSoftmax()
) Sequential(
  (conv_0): Conv2d(3, 5, kernel_size=(6, 6), stride=(1, 1), padding=(1, 1))
  (tanh_0): Tanh()
  (flatten): Flatten()
  (fc_0): Linear(in_features=4205, out_features=327, bias=True)
  (dropout_0): Dropout(p=0.39121718688057483)
  (classification_layer): Linear(in_features=327, out_features=10, bias=True)
  (sofmax): LogSoftmax()
)
Accuracy of the network on the 10000 test images: 41 %
Accuracy of plane : 53 %
Accuracy of   car : 54 %
Accuracy of  bird : 23 %
Accuracy of   cat : 22 %
Accuracy of  deer : 29 %
Accuracy of   dog : 38 %
Accuracy of  frog : 52 %
Accuracy of horse : 46 %
Accuracy of  ship : 49 %
Accuracy of truck : 40 %
Accuracy of the network on the 10000 test images: 38 %
Accuracy of plane : 32 %
Accuracy of   car : 51 %
Accuracy of  bird : 12 %
Accuracy of   cat :  6 %
Accuracy of  deer : 38 %
Accuracy of   dog : 23 %
Accuracy of  frog : 73 %
Accuracy of horse : 47 %
Accuracy of  ship : 48 %
Accuracy of truck : 50 %

new test:
train net 1, clone, test, train both nets, test again
goal with this test is to see if the added filter can make the clone perform better after it's been trained, like can it make up its deficit from the mutation after one round of training?
results:

maxshashoua@Maxs-MBP-2:~/Documents/Developer/othellofarm$ python3 exp.py 
previous_units: 3600


set up data:
Files already downloaded and verified
Files already downloaded and verified
training a net
/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
[1,  2000] loss: 1.798
[1,  4000] loss: 1.658
[1,  6000] loss: 1.560
[1,  8000] loss: 1.544
[1, 10000] loss: 1.518
[1, 12000] loss: 1.490
[2,  2000] loss: 1.393
[2,  4000] loss: 1.387
[2,  6000] loss: 1.417
[2,  8000] loss: 1.401
[2, 10000] loss: 1.419
[2, 12000] loss: 1.424
previous_units: 4500
Sequential(
  (conv_0): Conv2d(3, 4, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))
  (flatten): Flatten()
  (fc_0): Linear(in_features=3600, out_features=204, bias=True)
  (dropout_0): Dropout(p=0.047668292083812944)
  (relu_0): ReLU()
  (classification_layer): Linear(in_features=204, out_features=10, bias=True)
  (sofmax): LogSoftmax()
) Sequential(
  (conv_0): Conv2d(3, 5, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))
  (flatten): Flatten()
  (fc_0): Linear(in_features=4500, out_features=204, bias=True)
  (dropout_0): Dropout(p=0.047668292083812944)
  (relu_0): ReLU()
  (classification_layer): Linear(in_features=204, out_features=10, bias=True)
  (sofmax): LogSoftmax()
)
testing both nets, only first net trained
Accuracy of the network on the 10000 test images: 49 %
Accuracy of plane : 63 %
Accuracy of   car : 59 %
Accuracy of  bird : 42 %
Accuracy of   cat : 28 %
Accuracy of  deer : 39 %
Accuracy of   dog : 27 %
Accuracy of  frog : 63 %
Accuracy of horse : 58 %
Accuracy of  ship : 62 %
Accuracy of truck : 55 %
Accuracy of the network on the 10000 test images: 32 %
Accuracy of plane : 78 %
Accuracy of   car : 64 %
Accuracy of  bird : 22 %
Accuracy of   cat : 17 %
Accuracy of  deer :  4 %
Accuracy of   dog : 15 %
Accuracy of  frog :  7 %
Accuracy of horse : 40 %
Accuracy of  ship : 12 %
Accuracy of truck : 58 %
training both nets now
training a net
[1,  2000] loss: 1.289
[1,  4000] loss: 1.312
[1,  6000] loss: 1.319
[1,  8000] loss: 1.337
[1, 10000] loss: 1.358
[1, 12000] loss: 1.352
[2,  2000] loss: 1.226
[2,  4000] loss: 1.229
[2,  6000] loss: 1.268
[2,  8000] loss: 1.257
[2, 10000] loss: 1.290
[2, 12000] loss: 1.291
training a net
[1,  2000] loss: 1.350
[1,  4000] loss: 1.341
[1,  6000] loss: 1.339
[1,  8000] loss: 1.344
[1, 10000] loss: 1.333
[1, 12000] loss: 1.380
[2,  2000] loss: 1.213
[2,  4000] loss: 1.235
[2,  6000] loss: 1.263
[2,  8000] loss: 1.271
[2, 10000] loss: 1.311
[2, 12000] loss: 1.324
testing both nets, net 1 trained twice, net 2 cloned frm net 1 post first training, then trained again, so almost like 1.5x trained, where net 1 is 2x trained
Accuracy of the network on the 10000 test images: 50 %
Accuracy of plane : 47 %
Accuracy of   car : 56 %
Accuracy of  bird : 35 %
Accuracy of   cat : 22 %
Accuracy of  deer : 56 %
Accuracy of   dog : 40 %
Accuracy of  frog : 53 %
Accuracy of horse : 57 %
Accuracy of  ship : 73 %
Accuracy of truck : 60 %
Accuracy of the network on the 10000 test images: 50 %
Accuracy of plane : 63 %
Accuracy of   car : 52 %
Accuracy of  bird : 29 %
Accuracy of   cat : 22 %
Accuracy of  deer : 43 %
Accuracy of   dog : 49 %
Accuracy of  frog : 65 %
Accuracy of horse : 54 %
Accuracy of  ship : 65 %
Accuracy of truck : 58 %

so, i think this is a good place to stop. next step is to try the new filter if we have multiple conv layers. try to get this general cloning mutation thing for the conv part, then the fc part, then adding layers ok nice ok bai.


ok just fixed a bug in the compute_input_features for fc layer fn put the out_s+=2 inside the loop otherwise it would be wrong. now I can make nets with multiple conv layers, and the fc layer works out. i think it's time to move on to puttin that conv mutation anywhere on the multiple layers! but not today. today now is for climbing and hot sauce and music. goodbye...for now.
================______=================================
===============/      \==========================
==============/        \================================
=============/   @  @   \===============================
============|     <      |===============================
=============\          /================================
==============\ \___/  /================================
===============\______/=================================
=======================================================
Monday June 3 2019

today i fixed a bug that i knew i had made. It was this:

before today, I had successfully performed a mutation-cloning where the new net has the same weights and structure as the old net, except for the first (AND ONLY) conv layer now has one new filter. the second layer in the net (THE FIRST FC LAYER) updates to accomodate the new filters. yay,

what was new today was that I allowed for multiple convolutional layers. This means that the layer after the mutation is NO LONGER the first FC layer, and is instead a second convolutional layer. so what I did today was allow for that convolutional layer following the layer with the mutation to accomodate the extra channel it now has to listen to. The initializations of the layers were fine, but when i reassigned the weight.data of the layers, I never actually changed the shape of the tensors, so the model expedted the data to be bigger (have one more channel in) than it actually did. now this is fixed. 

the next step is to decide how to encode where the mutation happens, and let this conv filter addition occur anywhere in the convolutional section of the network.
=======================================================
Monday June 10, 2019

I generalized adding a conv filter to work on any layer i want. I'm getting an error when i try to clone a second time from the original:

build_info = rfn.randomize_network(bounded=False)
n0 = cmm.CustomModelMutable(build_info, 32, CUDA=False)
# print(n0.model)
n0_0 = n0.clone_with_added_filter(0)
n0_1 = n0.clone_with_added_filter(1) ## here's the error, it's a size mismatch runtime error on line 184. i'm worried im accidentally changing the original net so that when i try to clone again it doesn't work. nuts. 
=======================================================
wed june 12, 2019

did a few testies and figured out that if i'm cloneing and adding a filter to the same layer from the same parent net, 
i.e.:

n0_0 = n0.clone_with_added_filter(0) # also 1, 1 and 2, 2
n0_1 = n0.clone_with_added_filter(0)

, it doesn't break. hmmm. sizes of weights are all the same

=======================================================
Thurs June 13 2019

I figured out the bug! because i wasn't deep copying the build info, the info on net0 was being changed when i cloned it. so i added the deep copy and it's all good now.

next step now is to do the same thing but with fc layers. maybe first tho we'll test the mutation of the conv layers pls. okay. let's do testing bro

next step yah also is to re-implement point mutation bro

point mutation
fc mutation

doing a test now, pop of 10, 3 gens

=======================================================
Friday June 14, 2019 

ok just did a little test, it all works. adding conv filters done

todo:

- add conv filters DONE
- point mutation
- add conv layers
- add fc nodes
- add fc layers


                                                                      art
=======================================================
Wednesday June 26 2019

adding point mutation
added point mutation
testing now...

tested:

n = cmm.CustomModelMutable(rfn.randomize_network(bounded=True), 32, CUDA=False)
# a = copy.deepcopy(n.model.conv_0.weight.data)
train_net(n, 2)
test_nets([n])
n.apply_point_mutations(.01, 1/2)
test_nets([n])
....->

    training a net
/usr/local/Cellar/python3/3.6.3/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/torch/nn/modules/container.py:92: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.
  input = module(input)
[1,   500] loss: 2.135
[1,  1000] loss: 2.026
[2,   500] loss: 1.951
[2,  1000] loss: 1.909
Accuracy of the network on the 10000 test images: 35 %
mutated conv_0
mutated fc_0
mutated classification_layer
Accuracy of the network on the 10000 test images: 34 % ******* means that the mutation affected the behavior of the net!

trying again with bound of .1 instead of .01, expecting greater difference in accuracy...

awesome! got 17% down to 11% :)
funny that a successful test of this thing leads to a decrease in accuracy
=======================================================
Sunday June 30 2019

todo:

- add conv filters DONE
- point mutation DONE
- add conv layers
- add fc nodes DOING
- add fc layers

can't add nodes to the last linear layer because it's the classification layer brooooo dummieeeeeeee
adding a node to an fc layer modifies the shape of that layer's matrix and the matrix of the layer that follows
i.e. editing fc_0 changes 0 and 1, 1 changes 1 and 2 etc. oknice


i think i've got it, gotta test

so anyway here was my scratchwork for adding fc nodes:

'''
print('------------')

print(nn.Linear(2, 3).weight.data.size())
print(nn.Linear())

print('------------')

ins = 1
outs = 2
l0 = nn.Linear(ins, outs)
# ins = layer.weight.data.size()[1]
# outs = layer.weight.data.size()[0]

print(l0.weight.size())
# add node to this layer (add an out (init to 1's))
node=torch.ones(ins)
print(torch.cat((l0.weight.data, node.unsqueeze(0)), 0))

#node was added to prev layer, so edit this layer by adding ins to this one (init to 1s)
ins1 = 2
outs1 = 4
l1 = nn.Linear(ins1, outs1)
print(torch.cat((l1.weight.data, torch.ones(outs1).unsqueeze(1)), 1))

#yay!
'''
# l.weight.data

it's testing yay!

todo:

- add conv filters DONE
- point mutation DONE
- add conv layers 
- add fc nodes DONE
- add fc layers

let's add some layerz boi
conv layers:
i'm thinking to add them BEFORE the index that you specify so like add_conv_layer(0) would prepend a new layer, and (1) would add a layer after the first layer. for simplicity's sake, let's not add a conv layer after the last conv layer, only before, just cuz then the fc layers dont have to be modified

fc layers: same thing, let's only add after the first fc layer and before the classification layer
QUESTION: would there be a need to add a totally new last fc layer? and similar q re conv layers? and also re first layers? idk!

so just thinking about conv layers:
	we add a conv layer. 



=======================================================
=======================================================
=======================================================
=======================================================
